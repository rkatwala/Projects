
# Lunr-Based File Search with Sentence Extraction

## Overview
This Python script builds—or loads—an on-disk Lunr index (`index.json`) over all files in the current directory. It treats each file as a searchable “document,” with a special case for `basketball_sample.txt`: each non-empty line in that file becomes its own indexed document. When you run a search query, the script prints:

- The matching document ID
- The Lunr‐computed score
- Any sentence(s) from that document containing the matched term(s)

## Prerequisites
- Python 3.7 or newer
- A working virtual environment (recommended) with `lunr` installed:
  ```bash
  pip install lunr
````

## Files in This Directory

* **`search.py`**
  The main script that:

  1. Checks for an existing `index.json`.
  2. If none exists, scans all files:

     * Splits `basketball_sample.txt` into individual “docs” (one line = one document).
     * Indexes the contents of every other file as a single document.
  3. Serializes the built index to `index.json`.
  4. Accepts a search string via command-line arguments (e.g. `python search.py game NBA`).
  5. Runs the query against the Lunr index and prints matching sentences.

* **`basketball_sample.txt`** (optional)
  If present, this file’s non-empty lines are each indexed as their own “basketball\_N” document. Every other file in the same folder is indexed by filename.

* **`index.json`** (generated by `search.py`)
  A serialized Lunr index. On subsequent runs, `search.py` will load this instead of rebuilding the index from scratch.

## How to Use

1. **Activate your Python environment** (if you have one):

   ```bash
   source venv/bin/activate
   ```

2. **Install dependencies** (if not already installed):

   ```bash
   pip install lunr
   ```

3. **Place your files** in the same directory as `search.py`. If you have a `basketball_sample.txt` file with one fact per line, the script will index each non-empty line as a separate document named `basketball_1`, `basketball_2`, etc. Otherwise, every other file (e.g. `.txt`, `.md`, or source code) is indexed in its entirety.

4. **Run a search**:

   ```bash
   python search.py <term1> [term2 term3 …]
   ```

   Example:

   ```bash
   python search.py basketball NBA
   ```

   * On the first run, `index.json` will be built and saved.
   * On subsequent runs, `search.py` will detect `index.json` and load it, skipping re-indexing.
   * The script prints each matched document ID, its score, and the exact sentence(s) containing the search term(s).

## Example Output

```
Loaded existing index.json

Search results for “basketball NBA”:

doc=basketball_3    score=1.42
  → Basketball Fact #98: John Stockton holds the all-time NBA assist record.

doc=basketball_7    score=0.85
  → Basketball Fact #96: Oscar Schmidt holds the record for most points in an international career.
  → Basketball Fact #99: Kareem Abdul-Jabbar’s skyhook shot was nearly impossible to block.

doc=basketball_10   score=0.50
  → Basketball Fact #100: The NBA introduced coach’s challenges in 2019.

Index is now available in index.json
```

## How It Works

1. **Index Loading/Building**

   * If `index.json` already exists in the same directory, the script loads it and prints “Loaded existing index.json.”
   * If not, it scans all files (excluding `index.json`), splits `basketball_sample.txt` lines into separate documents, and indexes every other file’s full content. It then serializes the index to `index.json` and prints “Built a new index and wrote to index.json.”

2. **Document Text Mapping**

   * A helper function re-reads each file (or each line of `basketball_sample.txt`) to build an in-memory map of `doc_id → full_text`. This is needed to extract matching sentences after Lunr returns which terms matched.

3. **Search & Sentence Extraction**

   * The query string comes from command-line arguments.
   * Lunr returns a list of “hits,” each including a `MatchData` object whose `.metadata` keys are the matched terms.
   * The script pulls out those terms, looks up the full document text, splits it into sentences (on `.`, `?`, or `!`), and prints any sentence containing one of the matched terms (case-insensitive).

## Tips and Customization

* **Index Other File Types**
  By default, the script reads files as UTF-8 text. If you have PDFs, Word docs, or other binary formats, they will not index properly—either skip those or preprocess to plain text.

* **Filter by Extension**
  If you only want to index `.txt` or `.md` files, you can add a check in the loop:

  ```python
  if not filename.endswith(".txt"):
      continue
  ```

* **Sentence Splitting**
  The regex used (`r'(?<=[\.\?\!])\s+'`) is a simple approach and may not handle every edge case (e.g., ellipses, abbreviations). You can replace `extract_sentences_containing_terms` with a more robust sentence tokenizer (NLTK, spaCy, etc.) if needed.

* **Rebuilding the Index Manually**
  If you modify your files (add, remove, or edit), simply delete `index.json` and rerun:

  ```bash
  rm index.json
  python search.py <your-terms>
  ```

That’s it! You now have a directory-wide searchable index with Lunr, and each matching sentence is shown in context for easier review.
